{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kirk Vasilas - FE 520 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interfacing With Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to pull data from excel and analyze it in python.  The aim of this project is to use 3 different sized files and testing how long it takes to return and analyze them in each different method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excel is an analytical progra, first developed by Microsoft in 1985.  Its ability to store and analyze large amounts of data in one place has made it an industry staple for the financial world.  \n",
    "\n",
    "The only downside to excel is that the more complex the analysis, the more difficult it can be to accomplish.  The internal Code for such high level analytics is called VBA, Visual basic for application, which is an an outdated language.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Methodology "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hypothesis is that exporting a CSV will be the quickest and most efficient method of importing data from excel.\n",
    "\n",
    "\n",
    "The plan is to:\n",
    " - Import the same large excel file using each method\n",
    " - Read the file and return the value of the first cell\n",
    " - Use timeit.repeat to count return the time it takes for each of 10 tries\n",
    " - Calculate the max, min and average\n",
    " - Plot the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imported packages\n",
    "\n",
    "#Interface with excel\n",
    "import openpyxl \n",
    "import xlrd\n",
    "import pandas as pd\n",
    "\n",
    "#For analytics \n",
    "import timeit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using pandas and a csv file\n",
    "def csv_test():\n",
    "    appl = pd.read_csv(r\"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python37-32\\PythonCode\\FE520\\Homework\\files\\final_sample.csv\")\n",
    "    a1 = appl.iat[0,0]\n",
    "    return(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using openpyxl\n",
    "def pyxl_test():\n",
    "    wb = load_workbook(r'C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python37-32\\PythonCode\\FE520\\Homework\\files\\final_sample.xlsx')\n",
    "    sheet = wb.active\n",
    "    a1 = sheet['A1']\n",
    "    return(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Xlrd\n",
    "def xlrd_test():\n",
    "    workbook = xlrd.open_workbook(r'C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python37-32\\PythonCode\\FE520\\Homework\\files\\final_sample.xlsx')\n",
    "    worksheet = workbook.sheet_by_name('Sheet1')\n",
    "    curr_row = 0\n",
    "    row = worksheet.row(curr_row)\n",
    "    return(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(list):\n",
    "    return(sum(list) / len(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph(avg_list, max_list, min_list):\n",
    "    plt.plot(['csv','pyxl','xlrd'], avg_list, 'b.--', label = 'avg')\n",
    "    plt.plot(['csv','pyxl','xlrd'], max_list, 'r.--', label = 'max')\n",
    "    plt.plot(['csv','pyxl','xlrd'], min_list, 'g.--', label = 'min')\n",
    "    plt.xlabel('Import Method')\n",
    "    plt.ylabel('Time (s)')\n",
    "    plt.title(\"Average Time\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    return(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_result = timeit.repeat(\"csv_test()\", setup='from __main__ import csv_test', repeat = 10, number =10)\n",
    "pyxl_result = timeit.repeat(\"pyxl_test()\", setup='from __main__ import pyxl_test', repeat = 10, number =10)\n",
    "xlrd_result = timeit.repeat(\"xlrd_test()\", setup='from __main__ import xlrd_test', repeat = 10, number =10)\n",
    "\n",
    "avg_list = [avg(csv_result), avg(pyxl_result), avg(xlrd_result)]\n",
    "max_list = [max(csv_result), max(pyxl_result), max(xlrd_result)]\n",
    "min_list = [min(csv_result), min(pyxl_result), min(xlrd_result)]\n",
    "\n",
    "graph(avg_list, max_list, min_list )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Rank Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_avg = min(avg_list)\n",
    "max_avg = max(avg_list)\n",
    "abs_max = max(max_list)\n",
    "abs_min = min(min_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lowest average time was 0.039458 seconds using pandas and csv\n",
    "\n",
    "The highiest average time was 0.24896 seconds using openpyxl\n",
    "\n",
    "The lowest overall time was 0.036913 seconds using pandas and csv\n",
    "\n",
    "The highest overall time was 0.271957 seconds using openpyxl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The findings did support the hypothesis.  Pandas and csv migration is the fastest way to interface with excel.  However the xlrd package is not much slower at 0.12 seconds average and supports move intergration and file writing as well.\n",
    "\n",
    "Next steps would be to use different sample size files to see if one method was faster for one size file as opposed to a larger or smaller file.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
